{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential pattern mining(SPM)\n",
    "A **data-driven** technique with a wide range of applications is the **sequential pattern mining** (SPM). SPM consists of **discovering** useful **patterns** in the data, such\n",
    "as **frequent itemsets**, associations, sequential rules, or periodic patterns. In PdM,\n",
    "**SPM can provide useful information about associations between fault events as\n",
    "a sequence of minor faults or other events can potentially lead to a major failure**.\n",
    "Traditionally, SPM does not integrate the notion of time between the provided\n",
    "associations [14]. However, there are research works like [7] that allow the spec-\n",
    "ification of time constraints for the identification of the patterns, or works like\n",
    "[3] and [12] that provide solutions for an extension of SPM for online processing\n",
    "of temporal data sequences. The combination of such techniques with **Complex-\n",
    "event processing** (CEP) can predict failures in a variety of complex systems,\n",
    "such as the ones encountered in the industry.\n",
    "\n",
    "\n",
    "3. Ao, X., Luo, P., Li, C., Zhuang, F., He, Q.: Online frequent episode mining. In:IEEE 31st Int. Conf. on Data Engineering (ICDE). pp. 891-902 (2015)\n",
    "\n",
    "7. Hirate, Y., Yamana, H.: Generalized sequential pattern mining with item intervals.JCP 1(3), 51-60 (2006)\n",
    "\n",
    "12. Li, H., Peng, S., Li, J., Li, J., Cui, J., Ma, J.: Once and once+: Counting the frequency of time-constrained serial episodes in a streaming sequence. arXiv preprint arXiv:1801.09639 (2018)\n",
    "\n",
    "14. Wang, J., Li, C., Han, S., Sarkar, S., Zhou, X.: Predictive maintenance based on event-log analysis: A case study. IBM Journal of Research and Development 61(1), 11-121 (2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential pattern mining for PdM\n",
    "\n",
    "In this work, we will examine the\n",
    "**prediction effeciency** of a system that uses **SPM** with **time constraints between\n",
    "events**. An outline is presented in Algorithm 1, where the main input parameters\n",
    "consist of the **constraints** on the pattern period(**--minwi** , **--maxwi**) and the gap between events(**--minti** , **--maxti**), the\n",
    "a parameter, which sets the support threshold(**--conf**) in relation to the occurrence of\n",
    "faults in the training set, and ε, which keeps patterns not generating many false\n",
    "alarms.\n",
    "\n",
    "\n",
    "\n",
    "Algorithm 1 Sequential pattern mining for PdM\n",
    "-------------------------------------------------------------------\n",
    "procedure **Pattern Extraction**\n",
    "<br>\n",
    "**--------------------Hirate Yamana Algorithm(.jar Java)--------------------**\n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;nof<-number of failures\n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;min support<- (a * nof), 0<α<=1\n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;constraints<-set constraints on the pattern period and the gap between events\n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Extract frequent sequential patterns given min support and constraints \n",
    "<br>    \n",
    "**----------------------------SPM rules(.py Python)-----------------------------** \n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Keep only the partners ending in the target event E1E2E3...EnX\n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Result<-{}\n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;**for each** subset S of E1E2E3...En **do**\n",
    "<br>\n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**if** support(S) <= (1 + ε)*support(E1E2E3...EnX), ε>0 then\n",
    "<br>\n",
    "            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Result<-Result U S\n",
    "<br>\n",
    "\n",
    "procedure **Pattern Usage**\n",
    "<br>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;Continuously check whether any pattern in Result applies\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'argparser' was built under R version 3.6.2\"Warning message:\n",
      "\"package 'stringr' was built under R version 3.6.2\"Warning message:\n",
      "\"package 'data.table' was built under R version 3.6.2\""
     ]
    }
   ],
   "source": [
    "#Make the necessary imports.\n",
    "\n",
    "suppressMessages(library(argparser))\n",
    "suppressMessages(library(stringr))\n",
    "suppressMessages(library(data.table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an argument parser named p and keep there the necessary variables.\n",
    "\n",
    "p <- arg_parser(\"Implementation of the SPM+CEP Predictor\")\n",
    "\n",
    "# Add a positional argument\n",
    "p <- add_argument(p, \"train\", help=\"training dataset\")\n",
    "p <- add_argument(p, \"test\", help=\"test dataset\")\n",
    "\n",
    "p <- add_argument(p, \"tet\", help=\"type of the target fault events\",default=11)\n",
    "\n",
    "setwd(\"C:/Program Files (x86)\")\n",
    "p <- add_argument(p, \"--java\", help=\"the java path\", default=\"./Java/jdk1.8.0_192/bin/java.exe\")\n",
    "\n",
    "setwd(\"C:/Users/PETROS PETSINIS\")\n",
    "p <- add_argument(p, \"--python\", help=\"the python path\", default=\"./Anaconda/python.exe\")\n",
    "\n",
    "setwd(\"C:\")\n",
    "\n",
    "p <- add_argument(p, \"--cep\", help=\"complex event processing path\", default=\"C:/Users/Public/ptyxiakh/my_spmrules.py\")\n",
    "p <- add_argument(p, \"--spmf\", help=\"the spmf path\", default=\"C:/Users/Public/ptyxiakh/spmf.jar\")\n",
    "\n",
    "p <- add_argument(p, \"--conf\", help=\"minimum support (minsup)\", default=\"70%\")#50%\n",
    "\n",
    "p <- add_argument(p, \"--minti\", help=\"minimum time interval allowed between two succesive itemsets of a sequential pattern\", default=4)#2\n",
    "p <- add_argument(p, \"--maxti\", help=\"maximum time interval allowed between two succesive itemsets of a sequential pattern\", default=5)\n",
    "\n",
    "p <- add_argument(p, \"--minwi\", help=\"minimum time interval allowed between the first itemset and the last itemset of a sequential pattern\", default=4)#2\n",
    "p <- add_argument(p, \"--maxwi\", help=\"maximum time interval allowed between the first itemset and the last itemset of a sequential pattern\", default=5)\n",
    "\n",
    "p <- add_argument(p, \"--minwint\", help=\"min # of days before failure to expect a warning for true positive decision\", default=2)\n",
    "p <- add_argument(p, \"--maxwint\", help=\"max # of days before failure to expect a warning for true positive decision\", default=5)\n",
    "\n",
    "p <- add_argument(p, \"--csv\", help=\"output for csv\", default=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The data frame argv is:\"\n",
      "[[1]]\n",
      "[1] FALSE\n",
      "\n",
      "$help\n",
      "[1] FALSE\n",
      "\n",
      "$opts\n",
      "[1] NA\n",
      "\n",
      "$java\n",
      "[1] \"./Java/jdk1.8.0_192/bin/java.exe\"\n",
      "\n",
      "$python\n",
      "[1] \"./Anaconda/python.exe\"\n",
      "\n",
      "$cep\n",
      "[1] \"C:/Users/Public/ptyxiakh/my_spmrules.py\"\n",
      "\n",
      "$spmf\n",
      "[1] \"C:/Users/Public/ptyxiakh/spmf.jar\"\n",
      "\n",
      "$conf\n",
      "[1] \"70%\"\n",
      "\n",
      "$minti\n",
      "[1] 4\n",
      "\n",
      "$maxti\n",
      "[1] 5\n",
      "\n",
      "$minwi\n",
      "[1] 4\n",
      "\n",
      "$maxwi\n",
      "[1] 5\n",
      "\n",
      "$minwint\n",
      "[1] 2\n",
      "\n",
      "$maxwint\n",
      "[1] 5\n",
      "\n",
      "$csv\n",
      "[1] TRUE\n",
      "\n",
      "$train\n",
      "[1] \"C:/Users/Public/ptyxiakh/training_my_dataset2.csv\"\n",
      "\n",
      "$test\n",
      "[1] \"C:/Users/Public/ptyxiakh/testing_my_dataset2.csv\"\n",
      "\n",
      "$tet\n",
      "[1] 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define the necessary variables.\n",
    "\n",
    "argv = data.frame() #make a data frame named argv\n",
    "#if( length(commandArgs(trailingOnly = TRUE)) != 0){\n",
    "if(FALSE){\n",
    "  argv <- parse_args(p)\n",
    "} else {\n",
    "  #parse to argv the p's arguments as  argv <- parse_args(p,c(\"training dataset's path\",\"test dataset's path\",tet))  \n",
    "  argv <- parse_args(p,c(\"C:/Users/Public/ptyxiakh/training_my_dataset2.csv\",\"C:/Users/Public/ptyxiakh/testing_my_dataset2.csv\",11))\n",
    "}\n",
    "\n",
    "#init the variables\n",
    "train_path=argv$train\n",
    "test_path=argv$test\n",
    "\n",
    "spm_train_path = gsub(\".csv\",\"_spm.csv\",argv$train)\n",
    "spm_test_path = gsub(\".csv\",\"_spm.csv\",argv$test)\n",
    "spm_results_path = gsub(\".csv\",\"_results2.csv\",argv$train)\n",
    "\n",
    "target_event = argv$tet\n",
    "\n",
    "confidence = argv$conf\n",
    "\n",
    "min_dist_seq = argv$minti\n",
    "max_dist_seq = argv$maxti\n",
    "\n",
    "min_dist_first_last = argv$minwi\n",
    "max_dist_first_last = argv$maxwi\n",
    "\n",
    "max_warning_interval = argv$maxwint\n",
    "min_warning_interval = argv$minwint\n",
    "\n",
    "java_path = argv$java\n",
    "jspmf_path = argv$spmf\n",
    "\n",
    "python_path = argv$python\n",
    "cep_path = argv$cep\n",
    "\n",
    "csv = argv$csv\n",
    "\n",
    "print(\"The data frame argv is:\")\n",
    "print(argv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading function\n",
    "**function: read_dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for reading the csv file and save it to a two column table.\n",
    "\n",
    "read_dataset <- function(path){\n",
    "  dataset = read.table(path, header = TRUE, sep = \",\", dec = \".\", comment.char = \"#\")\n",
    "  dataset[, 2]  <- as.numeric(dataset[, 2])\n",
    "  return(dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train and test set\n",
    "\n",
    "The recorded log types read from csv files.\n",
    "One csv file(at **train_path**) has the **training_set** and the other(at **test_path**) the **testing_set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The test_set and training_set looks like:\"\n",
      "  Timestamps Event_id\n",
      "1 2014-01-21        1\n",
      "2 2014-01-21        3\n",
      "3 2014-01-21        4\n",
      "4 2014-01-21        5\n",
      "5 2014-01-21        6\n",
      "6 2014-01-21        5\n"
     ]
    }
   ],
   "source": [
    "#Reading train and test set.\n",
    "\n",
    "training_set = read_dataset(train_path)\n",
    "test_set =  read_dataset(test_path)\n",
    "\n",
    "print(\"The test_set and training_set looks like:\")\n",
    "print(head(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for creating and saving(as .csv file) spm episodes\n",
    "\n",
    "Split the table of the set to episodes. \n",
    "\n",
    "**episode** :the next day of a target event(or the start of the table) until the next target event(or the end of the table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for creating episodes list of each day's events.\n",
    "\n",
    "create_episodes_list_base_line <- function(target_event,ds,output){\n",
    "  if(!csv){\n",
    "    print(\"~~~~~~~CREATING FREQUENCY VECTORS~~~~~~~\")\n",
    "  }\n",
    "  #devide in episodes\n",
    "  target_event_spotted = FALSE\n",
    "    \n",
    "  #a list with data.frames for the episodes (each episode one data.frame)\n",
    "  episodes_list = list()\n",
    "    \n",
    "  #data.frame for episodes\n",
    "  episode_df <- data.frame(Timestamps=as.Date(character()),Event_id=integer())\n",
    "    \n",
    "  #iterate over every line of the original dataset\n",
    "  for(i in 1:nrow(ds)) {\n",
    "    #get the current row of the ds\n",
    "    meas <- ds[i,]\n",
    "      \n",
    "    #If it is the target event enable the appropriate flag\n",
    "    if((meas$Event_id == target_event) || i==1){\n",
    "      target_event_spotted = TRUE\n",
    "    }\n",
    "      \n",
    "    #fill the episode data.frame with the events that are between two target events\n",
    "    if(meas$Event_id != target_event && target_event_spotted){\n",
    "      episode_df <- rbind(episode_df,data.frame(Timestamps=meas$Timestamps, Event_id=meas$Event_id))  \n",
    "    } else if(meas$Event_id == target_event && target_event_spotted && is.data.frame(episode_df) && nrow(episode_df) != 0){\n",
    "      #a second occurness of the target event is spotted, close the episode\n",
    "      #target_event_spotted = FALSE\n",
    "      #aggregate by day all the events to form the segments inside the episodes\n",
    "      aggr_episode_df = aggregate(episode_df[ ,2], FUN=function(x){return(x)}, by=list(as.Date(episode_df$Timestamps, \"%Y-%m-%d\")))\n",
    "      \n",
    "      #add the episode to the episodes_list\n",
    "      episodes_list[[length(episodes_list)+1]] = aggr_episode_df\n",
    "        \n",
    "      #reset episode_df to en empty data.frame\n",
    "      episode_df <- data.frame(Timestamps=as.Date(character()),Event_id=integer())\n",
    "    }\n",
    "  }\n",
    "\n",
    "  print(\"Episode list looks like:\")\n",
    "  print((episodes_list))\n",
    "  print(\"-----------------------------------------------------\")\n",
    "\n",
    "  #if the file exists remove its content\n",
    "  if (file.exists(output)) {\n",
    "    invisible(file.remove(output))\n",
    "  }\n",
    "    \n",
    "  #output for HirateYamana\n",
    "  if(length(episodes_list)>0){\n",
    "    for(ep_index in (1:length(episodes_list))){\n",
    "      ep = episodes_list[[ep_index]]$x\n",
    "      ep_list = list()\n",
    "      for(i in (1:length(ep))){\n",
    "        ep_list[i] = paste(ep[[i]],collapse=\" \")\n",
    "      }\n",
    "      ep_list[length(ep_list)+1] = target_event\n",
    "      episode = \"\"\n",
    "      for(ep_lli in (1:length(ep_list))){\n",
    "        index = paste(paste(\"<\",ep_lli-1,sep=\"\"),\">\",sep=\"\") #I CHANGED IT FROM ep_lli to ep_lli-1\n",
    "        if(episode == \"\"){\n",
    "          episode = paste(index,ep_list[[ep_lli]],sep=\" \")\n",
    "        } else {\n",
    "          episode = paste(episode,paste(index,ep_list[[ep_lli]],sep=\" \"),sep=\" -1 \")\n",
    "        }\n",
    "      }\n",
    "      write(paste(episode,\"-1 -2\"),file=output,append=TRUE)\n",
    "    }\n",
    "  }  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create episodes list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"For the training set...\"\n",
      "[1] \"Episode list looks like:\"\n",
      "[[1]]\n",
      "      Group.1                               x\n",
      "1  2014-01-02                2, 4, 5, 7, 3, 6\n",
      "2  2014-01-03   1, 2, 3, 4, 6, 7, 8, 9, 7, 10\n",
      "3  2014-01-04                   3, 4, 5, 6, 8\n",
      "4  2014-01-05          1, 2, 3, 4, 5, 6, 7, 6\n",
      "5  2014-01-06             1, 2, 3, 4, 3, 9, 6\n",
      "6  2014-01-07       2, 3, 5, 6, 7, 8, 9, 7, 3\n",
      "7  2014-01-08   1, 2, 3, 4, 5, 6, 7, 3, 10, 4\n",
      "8  2014-01-09                      1, 2, 4, 5\n",
      "9  2014-01-10 1, 2, 3, 4, 5, 6, 7, 3, 9, 7, 7\n",
      "10 2014-01-11                   1, 3, 4, 3, 5\n",
      "\n",
      "[[2]]\n",
      "     Group.1                         x\n",
      "1 2014-01-12      2, 4, 5, 7, 4, 10, 5\n",
      "2 2014-01-13    1, 3, 4, 5, 6, 7, 8, 7\n",
      "3 2014-01-14 1, 2, 3, 4, 5, 6, 7, 8, 7\n",
      "4 2014-01-15                7, 8, 5, 7\n",
      "5 2014-01-16 1, 2, 3, 4, 5, 6, 7, 4, 7\n",
      "\n",
      "[[3]]\n",
      "     Group.1                         x\n",
      "1 2014-01-17             2, 4, 5, 7, 3\n",
      "2 2014-01-18       1, 3, 4, 5, 6, 7, 6\n",
      "3 2014-01-19 1, 2, 3, 4, 5, 7, 3, 4, 7\n",
      "4 2014-01-20    1, 2, 3, 6, 7, 3, 9, 6\n",
      "\n",
      "[1] \"-----------------------------------------------------\"\n",
      "[1] \"For the testing set...\"\n",
      "[1] \"Episode list looks like:\"\n",
      "[[1]]\n",
      "     Group.1                            x\n",
      "1 2014-01-21       1, 3, 4, 5, 6, 5, 6, 7\n",
      "2 2014-01-22          1, 2, 4, 5, 7, 8, 9\n",
      "3 2014-01-23      1, 2, 3, 5, 6, 8, 4, 10\n",
      "4 2014-01-24             3, 4, 5, 7, 5, 6\n",
      "5 2014-01-25 1, 2, 3, 4, 5, 6, 7, 8, 4, 7\n",
      "6 2014-01-26          1, 2, 4, 6, 7, 4, 7\n",
      "\n",
      "[[2]]\n",
      "     Group.1                         x\n",
      "1 2014-01-27       2, 3, 4, 5, 6, 7, 3\n",
      "2 2014-01-28   1, 2, 4, 5, 7, 3, 10, 5\n",
      "3 2014-01-29             3, 4, 7, 9, 7\n",
      "4 2014-01-30 1, 2, 3, 4, 5, 6, 3, 4, 6\n",
      "\n",
      "[1] \"-----------------------------------------------------\"\n",
      "[1] \"The .csv file of the test set looks like:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>&lt;0&gt; 1 3 4 5 6 5 6 7 -1 &lt;1&gt; 1 2 4 5 7 8 9 -1 &lt;2&gt; 1 2 3 5 6 8 4 10 -1 &lt;3&gt; 3 4 5 7 5 6 -1 &lt;4&gt; 1 2 3 4 5 6 7 8 4 7 -1 &lt;5&gt; 1 2 4 6 7 4 7 -1 &lt;6&gt; 11 -1 -2</td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 2 3 4 5 6 7 3 -1 &lt;1&gt; 1 2 4 5 7 3 10 5 -1 &lt;2&gt; 3 4 7 9 7 -1 &lt;3&gt; 1 2 3 4 5 6 3 4 6 -1 &lt;4&gt; 11 -1 -2                                                </span></td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " V1\\\\\n",
       "\\hline\n",
       "\t <0> 1 3 4 5 6 5 6 7 -1 <1> 1 2 4 5 7 8 9 -1 <2> 1 2 3 5 6 8 4 10 -1 <3> 3 4 5 7 5 6 -1 <4> 1 2 3 4 5 6 7 8 4 7 -1 <5> 1 2 4 6 7 4 7 -1 <6> 11 -1 -2\\\\\n",
       "\t <0> 2 3 4 5 6 7 3 -1 <1> 1 2 4 5 7 3 10 5 -1 <2> 3 4 7 9 7 -1 <3> 1 2 3 4 5 6 3 4 6 -1 <4> 11 -1 -2                                                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 |\n",
       "|---|\n",
       "| <0> 1 3 4 5 6 5 6 7 -1 <1> 1 2 4 5 7 8 9 -1 <2> 1 2 3 5 6 8 4 10 -1 <3> 3 4 5 7 5 6 -1 <4> 1 2 3 4 5 6 7 8 4 7 -1 <5> 1 2 4 6 7 4 7 -1 <6> 11 -1 -2 |\n",
       "| <0> 2 3 4 5 6 7 3 -1 <1> 1 2 4 5 7 3 10 5 -1 <2> 3 4 7 9 7 -1 <3> 1 2 3 4 5 6 3 4 6 -1 <4> 11 -1 -2                                                 |\n",
       "\n"
      ],
      "text/plain": [
       "  V1                                                                                                                                                 \n",
       "1 <0> 1 3 4 5 6 5 6 7 -1 <1> 1 2 4 5 7 8 9 -1 <2> 1 2 3 5 6 8 4 10 -1 <3> 3 4 5 7 5 6 -1 <4> 1 2 3 4 5 6 7 8 4 7 -1 <5> 1 2 4 6 7 4 7 -1 <6> 11 -1 -2\n",
       "2 <0> 2 3 4 5 6 7 3 -1 <1> 1 2 4 5 7 3 10 5 -1 <2> 3 4 7 9 7 -1 <3> 1 2 3 4 5 6 3 4 6 -1 <4> 11 -1 -2                                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if(!csv){\n",
    "  print(\"~~~~~~~SEQUENTIAL PATTERN MINING~~~~~~~\")\n",
    "}\n",
    "print(\"For the training set...\")\n",
    "create_episodes_list_base_line(target_event,training_set,spm_train_path)\n",
    "print(\"For the testing set...\")\n",
    "create_episodes_list_base_line(target_event,test_set,spm_test_path)\n",
    "\n",
    "print(\"The .csv file of the test set looks like:\")\n",
    "testset <- read.csv(file = spm_test_path,header=FALSE)\n",
    "head(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run HirateYamana algorithm \n",
    "\n",
    "Using a jar file named **spmf.jar**(jspmf_path) the **HirateYamana** algorithm is running for the **spm_train_path**(.csv file of the training set). \n",
    "\n",
    "Hirate Yamana: https://www.philippe-fournier-viger.com/spmf/hirateyamana.pdf\n",
    "\n",
    "Hirate Yamana example: https://www.philippe-fournier-viger.com/spmf/HirateYamana.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The .csv file of the HirateYamanas' results looks like:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 3 -1 &lt;4&gt; 11 -1  #SUP: 3    </span></td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 4 -1 &lt;4&gt; 11 -1  #SUP: 3    </span></td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 4 7 -1 &lt;4&gt; 11 -1  #SUP: 3  </span></td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 4 5 -1 &lt;4&gt; 11 -1  #SUP: 3  </span></td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 4 5 7 -1 &lt;4&gt; 11 -1  #SUP: 3</span></td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 5 -1 &lt;4&gt; 11 -1  #SUP: 3    </span></td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 5 7 -1 &lt;4&gt; 11 -1  #SUP: 3  </span></td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 7 -1 &lt;4&gt; 11 -1  #SUP: 3    </span></td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " V1\\\\\n",
       "\\hline\n",
       "\t <0> 3 -1 <4> 11 -1  \\#SUP: 3    \\\\\n",
       "\t <0> 4 -1 <4> 11 -1  \\#SUP: 3    \\\\\n",
       "\t <0> 4 7 -1 <4> 11 -1  \\#SUP: 3  \\\\\n",
       "\t <0> 4 5 -1 <4> 11 -1  \\#SUP: 3  \\\\\n",
       "\t <0> 4 5 7 -1 <4> 11 -1  \\#SUP: 3\\\\\n",
       "\t <0> 5 -1 <4> 11 -1  \\#SUP: 3    \\\\\n",
       "\t <0> 5 7 -1 <4> 11 -1  \\#SUP: 3  \\\\\n",
       "\t <0> 7 -1 <4> 11 -1  \\#SUP: 3    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 |\n",
       "|---|\n",
       "| <0> 3 -1 <4> 11 -1  #SUP: 3     |\n",
       "| <0> 4 -1 <4> 11 -1  #SUP: 3     |\n",
       "| <0> 4 7 -1 <4> 11 -1  #SUP: 3   |\n",
       "| <0> 4 5 -1 <4> 11 -1  #SUP: 3   |\n",
       "| <0> 4 5 7 -1 <4> 11 -1  #SUP: 3 |\n",
       "| <0> 5 -1 <4> 11 -1  #SUP: 3     |\n",
       "| <0> 5 7 -1 <4> 11 -1  #SUP: 3   |\n",
       "| <0> 7 -1 <4> 11 -1  #SUP: 3     |\n",
       "\n"
      ],
      "text/plain": [
       "  V1                             \n",
       "1 <0> 3 -1 <4> 11 -1  #SUP: 3    \n",
       "2 <0> 4 -1 <4> 11 -1  #SUP: 3    \n",
       "3 <0> 4 7 -1 <4> 11 -1  #SUP: 3  \n",
       "4 <0> 4 5 -1 <4> 11 -1  #SUP: 3  \n",
       "5 <0> 4 5 7 -1 <4> 11 -1  #SUP: 3\n",
       "6 <0> 5 -1 <4> 11 -1  #SUP: 3    \n",
       "7 <0> 5 7 -1 <4> 11 -1  #SUP: 3  \n",
       "8 <0> 7 -1 <4> 11 -1  #SUP: 3    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (file.exists(spm_results_path)) {\n",
    "  invisible(file.remove(spm_results_path))\n",
    "}\n",
    "\n",
    "javaOutput <- system(paste(java_path,\"-jar\",jspmf_path,\"run HirateYamana\",spm_train_path,spm_results_path,confidence,min_dist_seq,max_dist_seq,min_dist_first_last,max_dist_first_last), intern = TRUE)\n",
    "\n",
    "print(\"The .csv file of the HirateYamanas' results looks like:\")\n",
    "hiryamres <- read.csv(file = spm_results_path,header=FALSE)\n",
    "head(hiryamres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Rules and make predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The .csv file of the test set looks like:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>&lt;0&gt; 1 3 4 5 6 5 6 7 -1 &lt;1&gt; 1 2 4 5 7 8 9 -1 &lt;2&gt; 1 2 3 5 6 8 4 10 -1 &lt;3&gt; 3 4 5 7 5 6 -1 &lt;4&gt; 1 2 3 4 5 6 7 8 4 7 -1 &lt;5&gt; 1 2 4 6 7 4 7 -1 &lt;6&gt; 11 -1 -2</td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>&lt;0&gt; 2 3 4 5 6 7 3 -1 &lt;1&gt; 1 2 4 5 7 3 10 5 -1 &lt;2&gt; 3 4 7 9 7 -1 &lt;3&gt; 1 2 3 4 5 6 3 4 6 -1 &lt;4&gt; 11 -1 -2                                                </span></td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       " V1\\\\\n",
       "\\hline\n",
       "\t <0> 1 3 4 5 6 5 6 7 -1 <1> 1 2 4 5 7 8 9 -1 <2> 1 2 3 5 6 8 4 10 -1 <3> 3 4 5 7 5 6 -1 <4> 1 2 3 4 5 6 7 8 4 7 -1 <5> 1 2 4 6 7 4 7 -1 <6> 11 -1 -2\\\\\n",
       "\t <0> 2 3 4 5 6 7 3 -1 <1> 1 2 4 5 7 3 10 5 -1 <2> 3 4 7 9 7 -1 <3> 1 2 3 4 5 6 3 4 6 -1 <4> 11 -1 -2                                                \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 |\n",
       "|---|\n",
       "| <0> 1 3 4 5 6 5 6 7 -1 <1> 1 2 4 5 7 8 9 -1 <2> 1 2 3 5 6 8 4 10 -1 <3> 3 4 5 7 5 6 -1 <4> 1 2 3 4 5 6 7 8 4 7 -1 <5> 1 2 4 6 7 4 7 -1 <6> 11 -1 -2 |\n",
       "| <0> 2 3 4 5 6 7 3 -1 <1> 1 2 4 5 7 3 10 5 -1 <2> 3 4 7 9 7 -1 <3> 1 2 3 4 5 6 3 4 6 -1 <4> 11 -1 -2                                                 |\n",
       "\n"
      ],
      "text/plain": [
       "  V1                                                                                                                                                 \n",
       "1 <0> 1 3 4 5 6 5 6 7 -1 <1> 1 2 4 5 7 8 9 -1 <2> 1 2 3 5 6 8 4 10 -1 <3> 3 4 5 7 5 6 -1 <4> 1 2 3 4 5 6 7 8 4 7 -1 <5> 1 2 4 6 7 4 7 -1 <6> 11 -1 -2\n",
       "2 <0> 2 3 4 5 6 7 3 -1 <1> 1 2 4 5 7 3 10 5 -1 <2> 3 4 7 9 7 -1 <3> 1 2 3 4 5 6 3 4 6 -1 <4> 11 -1 -2                                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The python output is:\"\n",
      " [1] \"The rule keys are:\"                                          \n",
      " [2] \"dict_keys(['3', '4', '47', '45', '457', '5', '57', '7'])\"    \n",
      " [3] \"\"                                                            \n",
      " [4] \"-------------------------\"                                   \n",
      " [5] \"For episode 1\"                                               \n",
      " [6] \"-------------------------\"                                   \n",
      " [7] \"0> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      " [8] \"0> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      " [9] \"0> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[10] \"0> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[11] \"0> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[12] \"1> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[13] \"1> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[14] \"1> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[15] \"2> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[16] \"2> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[17] \"2> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[18] \"3> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[19] \"3> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[20] \"3> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[21] \"3> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[22] \"3> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[23] \"4> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[24] \"4> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[25] \"4> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[26] \"4> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[27] \"4> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[28] \"4> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[29] \"5> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[30] \"5> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[31] \"5> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[32] \"5> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[33] \"6> Failure\"                                                  \n",
      "[34] \"-------------------------\"                                   \n",
      "[35] \"For episode 2\"                                               \n",
      "[36] \"-------------------------\"                                   \n",
      "[37] \"0> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[38] \"0> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[39] \"0> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[40] \"0> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[41] \"0> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[42] \"1> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[43] \"1> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[44] \"1> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[45] \"1> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[46] \"1> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[47] \"2> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[48] \"2> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[49] \"2> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[50] \"2> Warning in 4 days expect a fault!, cause of rule: 7 -> 11\"\n",
      "[51] \"3> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[52] \"3> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[53] \"3> Warning in 4 days expect a fault!, cause of rule: 5 -> 11\"\n",
      "[54] \"3> Warning in 4 days expect a fault!, cause of rule: 3 -> 11\"\n",
      "[55] \"3> Warning in 4 days expect a fault!, cause of rule: 4 -> 11\"\n",
      "[56] \"4> Failure\"                                                  \n"
     ]
    }
   ],
   "source": [
    "setwd(\"C:/Users/PETROS PETSINIS\")\n",
    "pythonOutput <- system(paste(python_path,cep_path,spm_results_path,spm_test_path,target_event), intern = TRUE)\n",
    "\n",
    "print(\"The .csv file of the test set looks like:\")\n",
    "testset <- read.csv(file = spm_test_path,header=FALSE)\n",
    "head(testset)\n",
    "\n",
    "\n",
    "print(\"The python output is:\")\n",
    "print(pythonOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate spm results\n",
    "\n",
    "Calculating recall, precion and F1 score for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"-------------------\"\n",
      "[1] \"For episode:\"\n",
      "[1] 1\n",
      "[1] \"The serial number of the day, when the failure(target event) happens is:\"\n",
      "[1] 5\n",
      "[1] \"-------------------\"\n",
      "[1] \"For episode:\"\n",
      "[1] 2\n",
      "[1] \"The serial number of the day, when the failure(target event) happens is:\"\n",
      "[1] 3\n",
      "[1] \"------------------------------------------------------------\"\n",
      "dataset: C:/Users/Public/ptyxiakh/testing_my_dataset2.csv \n",
      "true_positives: 2 \n",
      "false_positives: 0 \n",
      "false_negatives: 0 \n",
      "precision: 1 \n",
      "recall: 1 \n",
      "F1: 1 \n"
     ]
    }
   ],
   "source": [
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "total_failures = 0\n",
    "\n",
    "day = 0\n",
    "\n",
    "warnings = list()\n",
    "\n",
    "ep_count=1\n",
    "\n",
    "#for every line of pythonOutput\n",
    "for(w in pythonOutput){ \n",
    "  #if string \"Warning\" appears in the line  \n",
    "  if(grepl(\"Warning \",w,fixed=TRUE)){\n",
    "    day = as.integer(str_extract(w, \"\\\\-*\\\\d+\\\\.*\\\\d*\")) #day's serial number  \n",
    "    warnings = c(warnings,day) #\n",
    "    #print(\"Waring list is:\")\n",
    "    #print(warnings)  \n",
    "  #if string \"Failure\" appears in the line     \n",
    "  } else if(grepl(\"Failure\",w,fixed=TRUE)){  \n",
    "      \n",
    "    print(\"-------------------\")  \n",
    "    print(\"For episode:\")\n",
    "    print(ep_count) \n",
    "    #print(\"-------------------\")\n",
    "    ep_count=ep_count+1  \n",
    "      \n",
    "    day = as.integer(str_extract(w, \"\\\\-*\\\\d+\\\\.*\\\\d*\")) #day's serial number \n",
    "      \n",
    "    total_failures = total_failures + 1 #increase total failures by 1\n",
    "    \n",
    "    day=day-1\n",
    "      \n",
    "    print(\"The serial number of the day, when the failure(target event) happens is:\")\n",
    "    print(day)  #day or day-1?\n",
    "    #print(\"-------------------\")\n",
    "      \n",
    "      \n",
    "    #if there is no warning  \n",
    "    if(length(warnings) == 0){\n",
    "      false_negatives = false_negatives + 1 #increase false negatives by 1\n",
    "    #if there is warning(s)    \n",
    "    } else {\n",
    "      if(length(warnings[warnings < day-max_warning_interval]) > 0){\n",
    "        #increase false positives by the number of these warnings\n",
    "        false_positives = false_positives + length(warnings[warnings < day-max_warning_interval]) \n",
    "      }\n",
    "        \n",
    "      #if there is warnings after the max and before the min interval from the failure(target event)   \n",
    "      if(length(warnings[warnings >= (day-max_warning_interval)]) > 0 & length(warnings[warnings <= (day-min_warning_interval)]) > 0){\n",
    "        true_positives = true_positives + 1 #increase true positives by 1\n",
    "      #if there is no correct warning    \n",
    "      } else {\n",
    "        false_negatives = false_negatives + 1 #increase false negatives by 1\n",
    "      }\n",
    "    }\n",
    "    warnings = list() #empty the list\n",
    "  }\n",
    "}\n",
    "\n",
    "precision = true_positives/(true_positives+false_positives) #calculate the precision of the model\n",
    "if((true_positives+false_positives) == 0){\n",
    "  precision = 0\n",
    "}\n",
    "\n",
    "recall = true_positives/total_failures #calculate recall of the model\n",
    "\n",
    "F1 = 2*((precision*recall)/(precision+recall)) #calculate F1 score of the model\n",
    "if(is.na((precision+recall)<=0.00)){\n",
    "  F1 = 0\n",
    "}\n",
    "\n",
    "#prints\n",
    "#if(!csv){\n",
    "print(\"------------------------------------------------------------\")\n",
    "if(TRUE){    \n",
    "  cat(paste(\"dataset:\",argv$test,\"\\ntrue_positives:\", true_positives,\"\\nfalse_positives:\", false_positives,\"\\nfalse_negatives:\", false_negatives,\"\\nprecision:\", precision,\"\\nrecall:\", recall,\"\\nF1:\", F1, \"\\n\"))\n",
    "} else {\n",
    "  cat(paste(argv$test,\",\", true_positives,\",\", false_positives,\",\", false_negatives,\",\", precision,\",\", recall,\",\", F1,\",\",argv$conf,\",\",argv$minti,\",\",argv$maxti,\",\",argv$minwi,\",\",argv$maxwi,\",\",argv$minwint,\",\",argv$maxwint, \"\\n\",sep=\"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
